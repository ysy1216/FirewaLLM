# FirewallLLM
By calling FirewallLLM, users can ensure the accuracy of the large model while greatly reducing the risk of privacy leakage when interacting with it.

With the development of large models, more and more users are using them for interactive Q&A. However, with the increasing volume of data, privacy issues have attracted widespread attention.So, we launched a privacy protection small model. Firstly, we will judge sensitive statements based on user questions, and secondly, we will handle sensitive statements accordingly. We guarantee that user privacy exposure may be greatly reduced when interacting with the model. Finally, we ensure the accuracy of large model interactions by restoring sensitive information. Experiments have shown that users interact with large models by calling small models. 

The FirewaLLM framework not only protects user data privacy, but also protects the accuracy of the interaction model.
